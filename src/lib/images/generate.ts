import OpenAI from 'openai'
import { toFile } from 'openai'

const XAI_API_BASE = 'https://api.x.ai/v1'

export const EDIT_PRESETS: Record<string, string> = {
  remove_background: 'Remove the background, keep only the main subject with a transparent or white background',
  enhance: 'Enhance the image quality, improve lighting and colors while keeping the same composition',
  style_oil: 'Transform this into an oil painting style with visible brush strokes',
  style_watercolor: 'Transform this into a watercolor painting with soft, flowing colors',
  style_sketch: 'Transform this into a detailed pencil sketch',
}

export async function generateGrokImages(prompt: string, n: number = 2) {
  const apiKey = process.env.XAI_API_KEY
  if (!apiKey) throw new Error('XAI_API_KEY not configured')

  const response = await fetch(`${XAI_API_BASE}/images/generations`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: 'grok-2-image',
      prompt,
      n: Math.min(n, 4),
    }),
  })

  if (!response.ok) {
    const err = await response.json().catch(() => ({}))
    throw new Error(err.error?.message || `Grok API error: ${response.status}`)
  }

  const data = await response.json()
  return (
    data.data?.map((img: { url?: string; b64_json?: string }) => ({
      url: img.url || (img.b64_json ? `data:image/png;base64,${img.b64_json}` : null),
    })).filter((img: { url: string | null }) => img.url) || []
  )
}

export async function generateOpenAIImages(gatewayKey: string, prompt: string, n: number = 2) {
  const response = await fetch('https://ai-gateway.vercel.sh/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${gatewayKey}`,
    },
    body: JSON.stringify({
      model: 'openai/gpt-5.2',
      messages: [{ role: 'user', content: `Create an image: ${prompt}` }],
    }),
  })

  if (!response.ok) {
    const err = await response.json().catch(() => ({}))
    throw new Error(err.error?.message || `OpenAI API error: ${response.status}`)
  }

  const result = await response.json()
  const message = result.choices?.[0]?.message
  const messageImages = message?.images as Array<{ type: string; image_url: { url: string } }> | undefined

  if (messageImages && messageImages.length > 0) {
    return messageImages
      .map(img => ({ url: img.image_url?.url || '' }))
      .filter(img => img.url)
  }

  // Fallback to Imagen if GPT-5.2 doesn't return images
  return generateImagenImages(gatewayKey, prompt, n)
}

export async function generateImagenImages(gatewayKey: string, prompt: string, n: number = 2) {
  const response = await fetch('https://ai-gateway.vercel.sh/v1/images/generations', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${gatewayKey}`,
    },
    body: JSON.stringify({
      model: 'google/imagen-4.0-generate-001',
      prompt,
      n: Math.min(n, 4),
    }),
  })

  if (!response.ok) {
    const err = await response.json().catch(() => ({}))
    throw new Error(err.error?.message || `Imagen API error: ${response.status}`)
  }

  const result = await response.json()
  const images = result.data as Array<{ url?: string; b64_json?: string }> | undefined

  if (!images || images.length === 0) {
    throw new Error('No images generated by Imagen')
  }

  return images
    .map(img => ({
      url: img.url || (img.b64_json ? `data:image/png;base64,${img.b64_json}` : ''),
    }))
    .filter(img => img.url)
}

export async function editImageWithDallE(
  gatewayKey: string,
  imageUrl: string,
  prompt: string,
  n: number = 1
) {
  let imageBuffer: Buffer

  if (imageUrl.startsWith('data:')) {
    const matches = imageUrl.match(/^data:([^;]+);base64,(.+)$/)
    if (!matches) throw new Error('Invalid base64 image format')
    imageBuffer = Buffer.from(matches[2], 'base64')
  } else {
    const imageResponse = await fetch(imageUrl)
    if (!imageResponse.ok) throw new Error('Failed to fetch source image')
    imageBuffer = Buffer.from(await imageResponse.arrayBuffer())
  }

  const mimeType = imageUrl.startsWith('data:')
    ? imageUrl.match(/^data:([^;]+);/)?.[1] || 'image/png'
    : 'image/png'

  const openai = new OpenAI({
    apiKey: gatewayKey,
    baseURL: 'https://ai-gateway.vercel.sh/v1',
  })

  const imageFile = await toFile(imageBuffer, 'image.png', { type: mimeType })

  const result = await openai.images.edit({
    model: 'dall-e-2',
    image: imageFile,
    prompt,
    n: Math.min(Math.max(1, n), 4),
    size: '1024x1024',
    response_format: 'b64_json',
  })

  const resultData = 'data' in result ? result.data : null
  if (!resultData || resultData.length === 0) {
    throw new Error('No images generated')
  }

  return resultData
    .map((img, index) => ({
      url: img.b64_json ? `data:image/png;base64,${img.b64_json}` : (img.url || ''),
      index,
    }))
    .filter(img => img.url)
}

/** Unified entry point for image generation */
export async function generateImages(
  prompt: string,
  provider: 'grok' | 'openai' | 'imagen',
  n: number = 2
): Promise<{ url: string }[]> {
  const gatewayKey = process.env.AI_GATEWAY_API_KEY

  if (provider === 'openai') {
    if (!gatewayKey) throw new Error('AI_GATEWAY_API_KEY not configured')
    return generateOpenAIImages(gatewayKey, prompt, n)
  } else if (provider === 'imagen') {
    if (!gatewayKey) throw new Error('AI_GATEWAY_API_KEY not configured')
    return generateImagenImages(gatewayKey, prompt, n)
  } else {
    return generateGrokImages(prompt, n)
  }
}
